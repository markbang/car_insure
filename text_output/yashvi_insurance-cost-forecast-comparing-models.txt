![](https://www.policybazaar.com/pblife/assets/images/pb_life_How_to_increase_Health_insurance_cover_1592063367.gif)

# About Dataset¶

This dataset contains person's information like
age,sex,gender,bmi,region,smoke or not and we have to predict their medical
insurance cost.In this notebook I will apply regression techniques of
supervised learning to predict the medical insurance costs.

# This notebook will cover the following¶

  1. Exploratory Data Analysis 
  2. Data Modelling and Evaluation

**Please Upvote my kernel if you like my work.**

# Import Libraries¶

In [1]:

    
    
    import pandas as pd
    import numpy as np
    import matplotlib.pyplot as plt
    import seaborn as sns
    sns.set_style("whitegrid")
    

# Import Dataset¶

In [2]:

    
    
    data=pd.read_csv('../input/insurance/insurance.csv')
    data.head()
    

Out[2]:

| age | sex | bmi | children | smoker | region | charges  
---|---|---|---|---|---|---|---  
0 | 19 | female | 27.900 | 0 | yes | southwest | 16884.92400  
1 | 18 | male | 33.770 | 1 | no | southeast | 1725.55230  
2 | 28 | male | 33.000 | 3 | no | southeast | 4449.46200  
3 | 33 | male | 22.705 | 0 | no | northwest | 21984.47061  
4 | 32 | male | 28.880 | 0 | no | northwest | 3866.85520  
  
**Exploratory Data Analysis**

# Data Summary¶

In [3]:

    
    
    data.iloc[:,[0,2,6]].describe()
    

Out[3]:

| age | bmi | charges  
---|---|---|---  
count | 1338.000000 | 1338.000000 | 1338.000000  
mean | 39.207025 | 30.663397 | 13270.422265  
std | 14.049960 | 6.098187 | 12110.011237  
min | 18.000000 | 15.960000 | 1121.873900  
25% | 27.000000 | 26.296250 | 4740.287150  
50% | 39.000000 | 30.400000 | 9382.033000  
75% | 51.000000 | 34.693750 | 16639.912515  
max | 64.000000 | 53.130000 | 63770.428010  
  
  * Age is ranging from 18 to 64 ,with mean of 38.2 and standard deviation of 14.04 
  * bmi is ranging from 15.96 to 53.13 , with mean of 30.6 and standard deviation of 6.09
  * charges is ranging from 1121 to 63770 , with mean of 13270 and standard deviation of 12110

# Age distribution¶

In [4]:

    
    
    sns.distplot(data['age'])
    

Out[4]:

    
    
    <matplotlib.axes._subplots.AxesSubplot at 0x7fdd15e94310>

![](__results___files/__results___14_1.png)

  * As you can see age is normally distrtibuted 
  * Maximum number of patients are of 18-22 age 

In [5]:

    
    
    sns.boxplot(y='age',data=data,color='green')
    

Out[5]:

    
    
    <matplotlib.axes._subplots.AxesSubplot at 0x7fdd15eecad0>

![](__results___files/__results___16_1.png)

# Age Vs Bmi by age¶

In [6]:

    
    
    sns.scatterplot(x="age", y="bmi", hue='sex',data=data,color='red')
    

Out[6]:

    
    
    <matplotlib.axes._subplots.AxesSubplot at 0x7fdd15bc8990>

![](__results___files/__results___18_1.png)

  * No relation between age and bmi

# Gender wise Age distribution¶

In [7]:

    
    
    sns.boxplot(x='sex',y='age',data=data)
    

Out[7]:

    
    
    <matplotlib.axes._subplots.AxesSubplot at 0x7fdd13ae9250>

![](__results___files/__results___21_1.png)

In [8]:

    
    
    f= plt.figure(figsize=(12,5))
    
    ax=f.add_subplot(121)
    sns.distplot(data[(data.sex == 'male')]["age"],color='b',ax=ax)
    ax.set_title('Distribution of ages of male')
    
    ax=f.add_subplot(122)
    sns.distplot(data[(data.sex == 'female')]['age'],color='r',ax=ax)
    ax.set_title('Distribution of ages of female')
    

Out[8]:

    
    
    Text(0.5, 1.0, 'Distribution of ages of female')

![](__results___files/__results___22_1.png)

  * As you can see age distribution of male and female are almost same .

# Age distribution of Smoker vs Non-Smoker¶

In [9]:

    
    
    sns.boxplot(x='smoker',y='age',data=data)
    

Out[9]:

    
    
    <matplotlib.axes._subplots.AxesSubplot at 0x7fdd12211b10>

![](__results___files/__results___25_1.png)

In [10]:

    
    
    f= plt.figure(figsize=(12,5))
    
    ax=f.add_subplot(121)
    sns.distplot(data[(data.smoker == 'yes')]["age"],color='#b0b0b0',ax=ax)
    ax.set_title('Distribution of ages of smoker')
    
    ax=f.add_subplot(122)
    sns.distplot(data[(data.smoker == 'no')]['age'],color='#333ed6',ax=ax)
    ax.set_title('Distribution of ages of non smoker')
    

Out[10]:

    
    
    Text(0.5, 1.0, 'Distribution of ages of non smoker')

![](__results___files/__results___26_1.png)

  * As you can see there is slight change in distribution of smoker and non smoker and also we can see there is some interesting spike in % of age group between 18-22.

# Smokers count by gender¶

In [11]:

    
    
    sns.catplot(x="smoker", kind="count",hue = 'sex',palette='GnBu',data=data)
    

Out[11]:

    
    
    <seaborn.axisgrid.FacetGrid at 0x7fdd15ea3ed0>

![](__results___files/__results___29_1.png)

  * There are more male smokers than female,but difference is not that big.
  * More non smokers patients than smokers patients .

# Cost distribution of smokers Vs non smokers¶

In [12]:

    
    
    sns.boxplot(x='smoker',y='charges',palette='viridis',data=data)
    

Out[12]:

    
    
    <matplotlib.axes._subplots.AxesSubplot at 0x7fdd15ea3e90>

![](__results___files/__results___32_1.png)

In [13]:

    
    
    f= plt.figure(figsize=(12,5))
    
    ax=f.add_subplot(121)
    sns.distplot(data[(data.smoker == 'yes')]["charges"],color='#b0b0b0',ax=ax)
    ax.set_title('Distribution of charges of smoker')
    
    ax=f.add_subplot(122)
    sns.distplot(data[(data.smoker == 'no')]['charges'],color='#333ed6',ax=ax)
    ax.set_title('Distribution of charges of non smoker')
    

Out[13]:

    
    
    Text(0.5, 1.0, 'Distribution of charges of non smoker')

![](__results___files/__results___33_1.png)

  * Smoking patients spend more 

# Charges of patients Age 18-22 of smokers Vs non-smokers¶

In [14]:

    
    
    sns.boxplot(x='smoker',y='charges',data=data[(data.age>=18)&(data.age<=22)])
    

Out[14]:

    
    
    <matplotlib.axes._subplots.AxesSubplot at 0x7fdd11d57c90>

![](__results___files/__results___36_1.png)

  * As we can see, patients of age 18-22 smokers spend much more on treatment than non-smokers. Although we can see some outliers om non smokers this may be due to some serious disease.

# Age vs charges of smokers¶

In [15]:

    
    
    sns.scatterplot(x="age", y="charges", data=data[data.smoker=='yes'],color='purple')
    

Out[15]:

    
    
    <matplotlib.axes._subplots.AxesSubplot at 0x7fdd11cc78d0>

![](__results___files/__results___39_1.png)

In [16]:

    
    
    g = sns.jointplot(x="age", y="charges", data=data[data.smoker=='yes'], kind="kde", color="b")
    g.plot_joint(plt.scatter, c="w", s=30, linewidth=1, marker="+")
    g.ax_joint.collections[0].set_alpha(0)
    g.set_axis_labels("age", "charges");
    

![](__results___files/__results___40_0.png)

In [17]:

    
    
    sns.jointplot(x="age", y="charges", data=data[data.smoker=='yes'], kind="kde");
    

![](__results___files/__results___41_0.png)

# Age vs Charges of Non-smokers¶

In [18]:

    
    
    sns.scatterplot(x="age", y="charges", data=data[data.smoker=='no'],color='#82113a')
    

Out[18]:

    
    
    <matplotlib.axes._subplots.AxesSubplot at 0x7fdd11986f50>

![](__results___files/__results___43_1.png)

In [19]:

    
    
    g = sns.jointplot(x="age", y="charges", data=data[data.smoker=='no'], kind="kde", color="#82113a")
    g.plot_joint(plt.scatter, c="w", s=30, linewidth=1, marker="+")
    g.ax_joint.collections[0].set_alpha(0)
    g.set_axis_labels("age", "charges");
    

![](__results___files/__results___44_0.png)

In [20]:

    
    
    sns.jointplot(x="age", y="charges", data=data[data.smoker=='no'],color='#82113a', kind="kde");
    

![](__results___files/__results___45_0.png)

  * In case of non smokers charges increase with age , but in case of smokers there is no such dependency.

# Bmi of Male Vs Female¶

In [21]:

    
    
    sns.boxplot(x='sex',y='bmi',palette='viridis',data=data)
    

Out[21]:

    
    
    <matplotlib.axes._subplots.AxesSubplot at 0x7fdd1184e550>

![](__results___files/__results___48_1.png)

In [22]:

    
    
    f= plt.figure(figsize=(12,5))
    
    ax=f.add_subplot(121)
    sns.distplot(data[(data.sex == 'male')]["bmi"],color='b',ax=ax)
    ax.set_title('Distribution of bmi of male')
    
    ax=f.add_subplot(122)
    sns.distplot(data[(data.sex == 'female')]['bmi'],color='r',ax=ax)
    ax.set_title('Distribution of bmi of female')
    

Out[22]:

    
    
    Text(0.5, 1.0, 'Distribution of bmi of female')

![](__results___files/__results___49_1.png)

  * Distribution of bmi of male and female are normally distributed

In [23]:

    
    
    f= plt.figure(figsize=(12,5))
    
    ax=f.add_subplot(121)
    sns.distplot(data[(data.smoker == 'yes')]["bmi"],color='#b0b0b0',ax=ax)
    ax.set_title('Distribution of bmi of smoker')
    
    ax=f.add_subplot(122)
    sns.distplot(data[(data.smoker == 'no')]['bmi'],color='#333ed6',ax=ax)
    ax.set_title('Distribution of bmi of non smoker')
    

Out[23]:

    
    
    Text(0.5, 1.0, 'Distribution of bmi of non smoker')

![](__results___files/__results___51_1.png)

  * distribution of bmi of smoker and non smoker are normally distributed

# Patients Region wise¶

In [24]:

    
    
    sns.catplot(x="region", kind="count",palette='viridis',data=data)
    

Out[24]:

    
    
    <seaborn.axisgrid.FacetGrid at 0x7fdd1155f110>

![](__results___files/__results___54_1.png)

In [25]:

    
    
    sns.catplot(x="region", kind="count",hue = 'sex',palette='viridis',data=data)
    

Out[25]:

    
    
    <seaborn.axisgrid.FacetGrid at 0x7fdd116a9e90>

![](__results___files/__results___55_1.png)

# Bmi vs Charges¶

In [26]:

    
    
    sns.lmplot(x="bmi", y="charges",data=data);
    

![](__results___files/__results___57_0.png)

# Bmi vs Charges of smoker Vs non smoker¶

In [27]:

    
    
    sns.lmplot(x="bmi", y="charges", hue="smoker", data=data, palette="Set1")
    

Out[27]:

    
    
    <seaborn.axisgrid.FacetGrid at 0x7fdd113edd50>

![](__results___files/__results___59_1.png)

In [28]:

    
    
    sns.lmplot(x="bmi", y="charges", hue="smoker", col="sex", data=data)
    

Out[28]:

    
    
    <seaborn.axisgrid.FacetGrid at 0x7fdd10b65b90>

![](__results___files/__results___60_1.png)

In [29]:

    
    
    sns.lmplot(x="bmi", y="charges", col="children", data=data,aspect=.5)
    

Out[29]:

    
    
    <seaborn.axisgrid.FacetGrid at 0x7fdd10a68c10>

![](__results___files/__results___61_1.png)

In [30]:

    
    
    g = sns.jointplot(x="bmi", y="charges", data=data, kind="kde", color="#4837cc")
    g.plot_joint(plt.scatter, c="w", s=30, linewidth=1, marker="+")
    g.ax_joint.collections[0].set_alpha(0)
    g.set_axis_labels("bmi", "charges")
    

Out[30]:

    
    
    <seaborn.axisgrid.JointGrid at 0x7fdd10a68dd0>

![](__results___files/__results___62_1.png)

# Childrens Vs Charges¶

In [31]:

    
    
    sns.catplot(x="children", kind="count",palette='rainbow',data=data)
    

Out[31]:

    
    
    <seaborn.axisgrid.FacetGrid at 0x7fdd11c12d90>

![](__results___files/__results___64_1.png)

In [32]:

    
    
    sns.lmplot(x="children", y="charges",data=data)
    

Out[32]:

    
    
    <seaborn.axisgrid.FacetGrid at 0x7fdd11553c10>

![](__results___files/__results___65_1.png)

In [33]:

    
    
    sns.lmplot(x="children", y="charges", hue='smoker',data=data)
    

Out[33]:

    
    
    <seaborn.axisgrid.FacetGrid at 0x7fdd11c23a90>

![](__results___files/__results___66_1.png)

# Correlation matrix¶

In [34]:

    
    
    f, ax = plt.subplots(figsize=(10, 8))
    corr = data.corr()
    sns.heatmap(corr)
    

Out[34]:

    
    
    <matplotlib.axes._subplots.AxesSubplot at 0x7fdd105b8650>

![](__results___files/__results___68_1.png)

**Data Modelling and Evaluation**

In [35]:

    
    
    from sklearn.model_selection import train_test_split
    from sklearn import linear_model
    from sklearn.preprocessing import PolynomialFeatures
    from sklearn.pipeline import make_pipeline
    from sklearn.linear_model import LinearRegression
    from sklearn.preprocessing import LabelEncoder
    from sklearn.model_selection import cross_val_score
    from sklearn.tree import DecisionTreeRegressor
    from sklearn.ensemble import RandomForestRegressor
    from sklearn.metrics import r2_score,mean_squared_error
    

# Create dummy variables¶

In [36]:

    
    
    #sex
    le = LabelEncoder()
    le.fit(data.sex.drop_duplicates()) 
    data.sex = le.transform(data.sex)
    # smoker or not
    le.fit(data.smoker.drop_duplicates()) 
    data.smoker = le.transform(data.smoker)
    #region
    le.fit(data.region.drop_duplicates()) 
    data.region = le.transform(data.region)
    

In [37]:

    
    
    data.head()
    

Out[37]:

| age | sex | bmi | children | smoker | region | charges  
---|---|---|---|---|---|---|---  
0 | 19 | 0 | 27.900 | 0 | 1 | 3 | 16884.92400  
1 | 18 | 1 | 33.770 | 1 | 0 | 2 | 1725.55230  
2 | 28 | 1 | 33.000 | 3 | 0 | 2 | 4449.46200  
3 | 33 | 1 | 22.705 | 0 | 0 | 1 | 21984.47061  
4 | 32 | 1 | 28.880 | 0 | 0 | 1 | 3866.85520  
  
# Train Test split¶

In [38]:

    
    
    x = data.drop(['charges','region'], axis = 1)
    y = data.charges
    
    x_train,x_test,y_train,y_test = train_test_split(x,y, random_state = 0)
    

# Linear regression¶

In [39]:

    
    
    lreg = linear_model.LinearRegression()
    lreg.fit(x_train,y_train)
    y_train_pred = lreg.predict(x_train)
    y_test_pred = lreg.predict(x_test)
    lreg.score(x_test,y_test)
    

Out[39]:

    
    
    0.7952171980481992

# Polynomial Regression¶

In [40]:

    
    
    degree=2
    polyreg=make_pipeline(PolynomialFeatures(degree),LinearRegression())
    polyreg.fit(x_train,y_train)
    y_train_pred = polyreg.predict(x_train)
    y_test_pred = polyreg.predict(x_test)
    polyreg.score(x_test,y_test)
    

Out[40]:

    
    
    0.8849197344147234

# Decision Tree Regressor¶

In [41]:

    
    
    dt_regressor = DecisionTreeRegressor(random_state=0)
    cross_val_score(dt_regressor,x_train, y_train, cv=10).mean()
    

Out[41]:

    
    
    0.6505624931708361

# Random Forest Regressor¶

In [42]:

    
    
    Rf = RandomForestRegressor(n_estimators = 100,
                                  criterion = 'mse',
                                  random_state = 1,
                                  n_jobs = -1)
    Rf.fit(x_train,y_train)
    Rf_train_pred = Rf.predict(x_train)
    Rf_test_pred = Rf.predict(x_test)
    
    
    r2_score(y_test,Rf_test_pred)
    

Out[42]:

    
    
    0.8681209840318433

# Conclusion¶

  * Got maximum score of 0.88 from polynomial regression
  * Although random forest regressor performing good with an accuracy 0.86

**I hope you enjoyed this kernel ,also if you have any suggestions to improve
my model ,then feel free to comment it down .**

![](https://i.pinimg.com/originals/71/c0/68/71c068478e7499d73ec005eacbe42c10.gif)

