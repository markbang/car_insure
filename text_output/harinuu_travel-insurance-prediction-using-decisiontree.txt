In [1]:

    
    
    import numpy as np
    import pandas as pd
    import matplotlib.pyplot as plt 
    import seaborn as sns
    %matplotlib inline
    

# import the dataset from kaggle¶

In [2]:

    
    
    df=pd.read_csv("/kaggle/input/travel-insurance-prediction-data/TravelInsurancePrediction.csv")
    

# EDA¶

In [3]:

    
    
    df.head()
    

Out[3]:

| Unnamed: 0 | Age | Employment Type | GraduateOrNot | AnnualIncome | FamilyMembers | ChronicDiseases | FrequentFlyer | EverTravelledAbroad | TravelInsurance  
---|---|---|---|---|---|---|---|---|---|---  
0 | 0 | 31 | Government Sector | Yes | 400000 | 6 | 1 | No | No | 0  
1 | 1 | 31 | Private Sector/Self Employed | Yes | 1250000 | 7 | 0 | No | No | 0  
2 | 2 | 34 | Private Sector/Self Employed | Yes | 500000 | 4 | 1 | No | No | 1  
3 | 3 | 28 | Private Sector/Self Employed | Yes | 700000 | 3 | 1 | No | No | 0  
4 | 4 | 28 | Private Sector/Self Employed | Yes | 700000 | 8 | 1 | Yes | No | 0  
  
In [4]:

    
    
    df.drop(columns=["Unnamed: 0"], inplace=True)
    

In [5]:

    
    
    df.isnull().sum()
    

Out[5]:

    
    
    Age                    0
    Employment Type        0
    GraduateOrNot          0
    AnnualIncome           0
    FamilyMembers          0
    ChronicDiseases        0
    FrequentFlyer          0
    EverTravelledAbroad    0
    TravelInsurance        0
    dtype: int64

In [6]:

    
    
    df.replace('-','nan')
    df.replace('na','nan')
    

Out[6]:

| Age | Employment Type | GraduateOrNot | AnnualIncome | FamilyMembers | ChronicDiseases | FrequentFlyer | EverTravelledAbroad | TravelInsurance  
---|---|---|---|---|---|---|---|---|---  
0 | 31 | Government Sector | Yes | 400000 | 6 | 1 | No | No | 0  
1 | 31 | Private Sector/Self Employed | Yes | 1250000 | 7 | 0 | No | No | 0  
2 | 34 | Private Sector/Self Employed | Yes | 500000 | 4 | 1 | No | No | 1  
3 | 28 | Private Sector/Self Employed | Yes | 700000 | 3 | 1 | No | No | 0  
4 | 28 | Private Sector/Self Employed | Yes | 700000 | 8 | 1 | Yes | No | 0  
... | ... | ... | ... | ... | ... | ... | ... | ... | ...  
1982 | 33 | Private Sector/Self Employed | Yes | 1500000 | 4 | 0 | Yes | Yes | 1  
1983 | 28 | Private Sector/Self Employed | Yes | 1750000 | 5 | 1 | No | Yes | 0  
1984 | 28 | Private Sector/Self Employed | Yes | 1150000 | 6 | 1 | No | No | 0  
1985 | 34 | Private Sector/Self Employed | Yes | 1000000 | 6 | 0 | Yes | Yes | 1  
1986 | 34 | Private Sector/Self Employed | Yes | 500000 | 4 | 0 | No | No | 0  
  
1987 rows Ã 9 columns

In [7]:

    
    
    df.isnull().sum()
    

Out[7]:

    
    
    Age                    0
    Employment Type        0
    GraduateOrNot          0
    AnnualIncome           0
    FamilyMembers          0
    ChronicDiseases        0
    FrequentFlyer          0
    EverTravelledAbroad    0
    TravelInsurance        0
    dtype: int64

In [8]:

    
    
    df.info()
    
    
    
    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 1987 entries, 0 to 1986
    Data columns (total 9 columns):
     #   Column               Non-Null Count  Dtype 
    ---  ------               --------------  ----- 
     0   Age                  1987 non-null   int64 
     1   Employment Type      1987 non-null   object
     2   GraduateOrNot        1987 non-null   object
     3   AnnualIncome         1987 non-null   int64 
     4   FamilyMembers        1987 non-null   int64 
     5   ChronicDiseases      1987 non-null   int64 
     6   FrequentFlyer        1987 non-null   object
     7   EverTravelledAbroad  1987 non-null   object
     8   TravelInsurance      1987 non-null   int64 
    dtypes: int64(5), object(4)
    memory usage: 139.8+ KB
    

In [9]:

    
    
    df["TravelInsurance"]= df["TravelInsurance"].map({0: "not purchased", 1: "purchased"})
    

In [10]:

    
    
    df.skew()
    
    
    
    /opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.
      """Entry point for launching an IPython kernel.
    

Out[10]:

    
    
    Age                0.239625
    AnnualIncome       0.078417
    FamilyMembers      0.561197
    ChronicDiseases    0.992872
    dtype: float64

# FINDING CORRELATION¶

In [11]:

    
    
    cor=df.corr()
    cor
    

Out[11]:

| Age | AnnualIncome | FamilyMembers | ChronicDiseases  
---|---|---|---|---  
Age | 1.000000 | -0.020101 | 0.027409 | 0.007359  
AnnualIncome | -0.020101 | 1.000000 | -0.015367 | -0.001149  
FamilyMembers | 0.027409 | -0.015367 | 1.000000 | 0.028209  
ChronicDiseases | 0.007359 | -0.001149 | 0.028209 | 1.000000  
  
In [12]:

    
    
    import plotly.express as px
    df=df
    figure=px.histogram(df, x="Age", color= "TravelInsurance", title= "Factors affecting purchase of travel insurance: age")
    figure.show()
    

In [13]:

    
    
    import plotly.express as px
    df=df
    figure=px.histogram(df, x="Employment Type", color= "TravelInsurance", title= "Factors affecting purchase of travel insurance: age")
    figure.show()
    

In [14]:

    
    
    import plotly.express as px
    df=df
    figure=px.histogram(df, x="AnnualIncome", color= "TravelInsurance", title= "Factors affecting purchase of travel insurance: age")
    figure.show()
    

In [15]:

    
    
    df["GraduateOrNot"]=df["GraduateOrNot"].map({"No":0, "Yes":1})
    df["FrequentFlyer"]=df["FrequentFlyer"].map({"No":0, "Yes":1})
    df["EverTravelledAbroad"]=df["EverTravelledAbroad"].map({"No":0, "Yes":1})
    

# FEATURE ENGINEERING¶

In [16]:

    
    
    x=np.array(df[["Age","GraduateOrNot", "AnnualIncome","FamilyMembers", "ChronicDiseases","FrequentFlyer","EverTravelledAbroad"]])
    y=np.array(df[["TravelInsurance"]])
    

# DECISIONTREE¶

In [17]:

    
    
    from sklearn.model_selection import train_test_split
    from sklearn.tree import DecisionTreeClassifier
    xtrain, xtest, ytrain, ytest= train_test_split(x,y, test_size=0.10, random_state=42)
    model = DecisionTreeClassifier()
    

In [18]:

    
    
    model.fit(xtrain, ytrain)
    

Out[18]:

    
    
    DecisionTreeClassifier()

In [19]:

    
    
    predictions=model.predict(xtest)
    

In [20]:

    
    
    predictions
    

Out[20]:

    
    
    array(['not purchased', 'purchased', 'not purchased', 'purchased',
           'purchased', 'purchased', 'not purchased', 'not purchased',
           'not purchased', 'not purchased', 'purchased', 'purchased',
           'purchased', 'not purchased', 'not purchased', 'purchased',
           'not purchased', 'not purchased', 'not purchased', 'not purchased',
           'not purchased', 'purchased', 'not purchased', 'not purchased',
           'not purchased', 'not purchased', 'not purchased', 'not purchased',
           'not purchased', 'not purchased', 'not purchased', 'not purchased',
           'purchased', 'not purchased', 'not purchased', 'not purchased',
           'not purchased', 'not purchased', 'not purchased', 'not purchased',
           'purchased', 'not purchased', 'not purchased', 'purchased',
           'not purchased', 'not purchased', 'not purchased', 'purchased',
           'purchased', 'not purchased', 'not purchased', 'not purchased',
           'not purchased', 'purchased', 'not purchased', 'purchased',
           'purchased', 'not purchased', 'not purchased', 'not purchased',
           'not purchased', 'not purchased', 'not purchased', 'not purchased',
           'not purchased', 'purchased', 'purchased', 'not purchased',
           'not purchased', 'purchased', 'not purchased', 'not purchased',
           'not purchased', 'not purchased', 'purchased', 'not purchased',
           'purchased', 'purchased', 'not purchased', 'purchased',
           'purchased', 'not purchased', 'not purchased', 'not purchased',
           'purchased', 'not purchased', 'not purchased', 'not purchased',
           'purchased', 'not purchased', 'not purchased', 'not purchased',
           'not purchased', 'purchased', 'purchased', 'not purchased',
           'purchased', 'purchased', 'not purchased', 'not purchased',
           'not purchased', 'purchased', 'not purchased', 'not purchased',
           'purchased', 'purchased', 'not purchased', 'not purchased',
           'not purchased', 'not purchased', 'purchased', 'not purchased',
           'not purchased', 'not purchased', 'purchased', 'not purchased',
           'not purchased', 'not purchased', 'purchased', 'not purchased',
           'not purchased', 'not purchased', 'not purchased', 'not purchased',
           'not purchased', 'purchased', 'purchased', 'not purchased',
           'not purchased', 'purchased', 'not purchased', 'not purchased',
           'not purchased', 'not purchased', 'not purchased', 'not purchased',
           'not purchased', 'not purchased', 'not purchased', 'not purchased',
           'not purchased', 'purchased', 'not purchased', 'purchased',
           'not purchased', 'not purchased', 'not purchased', 'not purchased',
           'not purchased', 'purchased', 'not purchased', 'purchased',
           'not purchased', 'purchased', 'purchased', 'purchased',
           'not purchased', 'not purchased', 'not purchased', 'not purchased',
           'purchased', 'not purchased', 'purchased', 'not purchased',
           'purchased', 'not purchased', 'not purchased', 'not purchased',
           'purchased', 'not purchased', 'not purchased', 'not purchased',
           'purchased', 'purchased', 'not purchased', 'not purchased',
           'not purchased', 'purchased', 'purchased', 'not purchased',
           'not purchased', 'purchased', 'not purchased', 'purchased',
           'not purchased', 'purchased', 'purchased', 'not purchased',
           'not purchased', 'not purchased', 'not purchased', 'not purchased',
           'not purchased', 'purchased', 'not purchased', 'not purchased',
           'not purchased', 'not purchased', 'not purchased'], dtype=object)

In [21]:

    
    
    from sklearn.metrics import accuracy_score, confusion_matrix
    print(accuracy_score(ytest,predictions))
    
    
    
    0.8190954773869347
    

