In [1]:

    
    
    # ìííê²½ ì¸í (ì½ë ë³ê²½ X)
    import pandas as pd
    import numpy as np
    from sklearn.model_selection import train_test_split
    
    def exam_data_load(df, target, id_name="", null_name=""):
        if id_name == "":
            df = df.reset_index().rename(columns={"index": "id"})
            id_name = 'id'
        else:
            id_name = id_name
        
        if null_name != "":
            df[df == null_name] = np.nan
        
        X_train, X_test = train_test_split(df, test_size=0.2, random_state=2021)
        
        y_train = X_train[[id_name, target]]
        X_train = X_train.drop(columns=[target])
    
        
        y_test = X_test[[id_name, target]]
        X_test = X_test.drop(columns=[target])
        return X_train, X_test, y_train, y_test 
        
    df = pd.read_csv("../input/insurance/insurance.csv")
    X_train, X_test, y_train, y_test = exam_data_load(df, target='charges')
    
    X_train.shape, X_test.shape, y_train.shape, y_test.shape
    

Out[1]:

    
    
    ((1070, 7), (268, 7), (1070, 2), (268, 2))

# EDA¶

In [2]:

    
    
    X_train.head()
    

Out[2]:

| id | age | sex | bmi | children | smoker | region  
---|---|---|---|---|---|---|---  
209 | 209 | 40 | male | 41.230 | 1 | no | northeast  
540 | 540 | 34 | female | 38.000 | 3 | no | southwest  
747 | 747 | 19 | male | 21.755 | 0 | no | northwest  
39 | 39 | 60 | male | 39.900 | 0 | yes | southwest  
640 | 640 | 33 | male | 42.400 | 5 | no | southwest  
  
In [3]:

    
    
    y_train.head()
    

Out[3]:

| id | charges  
---|---|---  
209 | 209 | 6610.10970  
540 | 540 | 6196.44800  
747 | 747 | 1627.28245  
39 | 39 | 48173.36100  
640 | 640 | 6666.24300  
  
In [4]:

    
    
    y_train['charges'].hist()
    

Out[4]:

    
    
    <AxesSubplot:>

![](__results___files/__results___4_1.png)

In [5]:

    
    
    X_train.isnull().sum()
    

Out[5]:

    
    
    id          0
    age         0
    sex         0
    bmi         0
    children    0
    smoker      0
    region      0
    dtype: int64

In [6]:

    
    
    X_test.isnull().sum()
    

Out[6]:

    
    
    id          0
    age         0
    sex         0
    bmi         0
    children    0
    smoker      0
    region      0
    dtype: int64

In [7]:

    
    
    X_train.info()
    
    
    
    <class 'pandas.core.frame.DataFrame'>
    Int64Index: 1070 entries, 209 to 1140
    Data columns (total 7 columns):
     #   Column    Non-Null Count  Dtype  
    ---  ------    --------------  -----  
     0   id        1070 non-null   int64  
     1   age       1070 non-null   int64  
     2   sex       1070 non-null   object 
     3   bmi       1070 non-null   float64
     4   children  1070 non-null   int64  
     5   smoker    1070 non-null   object 
     6   region    1070 non-null   object 
    dtypes: float64(1), int64(3), object(3)
    memory usage: 66.9+ KB
    

In [8]:

    
    
    X_train.select_dtypes("object").columns
    

Out[8]:

    
    
    Index(['sex', 'smoker', 'region'], dtype='object')

In [9]:

    
    
    # Train ['sex', 'smoker', 'region']
    cols = X_train.select_dtypes("object").columns
    
    for col in cols:
        print("\n=====", col, "=====")
        print("[train]")
        print(X_train[col].value_counts())
        print("[test]")
        print(X_test[col].value_counts())
    
    
    
    ===== sex =====
    [train]
    male      551
    female    519
    Name: sex, dtype: int64
    [test]
    female    143
    male      125
    Name: sex, dtype: int64
    
    ===== smoker =====
    [train]
    no     845
    yes    225
    Name: smoker, dtype: int64
    [test]
    no     219
    yes     49
    Name: smoker, dtype: int64
    
    ===== region =====
    [train]
    southeast    304
    northeast    266
    southwest    261
    northwest    239
    Name: region, dtype: int64
    [test]
    northwest    86
    southwest    64
    southeast    60
    northeast    58
    Name: region, dtype: int64
    

# Preprocessing¶

## Categorical Variables¶

In [10]:

    
    
    X_train = pd.get_dummies(X_train, columns = cols)
    X_test = pd.get_dummies(X_test, columns = cols)
    

In [11]:

    
    
    X_train.head(2)
    

Out[11]:

| id | age | bmi | children | sex_female | sex_male | smoker_no | smoker_yes | region_northeast | region_northwest | region_southeast | region_southwest  
---|---|---|---|---|---|---|---|---|---|---|---|---  
209 | 209 | 40 | 41.23 | 1 | 0 | 1 | 1 | 0 | 1 | 0 | 0 | 0  
540 | 540 | 34 | 38.00 | 3 | 1 | 0 | 1 | 0 | 0 | 0 | 0 | 1  
  
## Log Transform¶

In [12]:

    
    
    y_train['charges'].hist()
    

Out[12]:

    
    
    <AxesSubplot:>

![](__results___files/__results___15_1.png)

In [13]:

    
    
    y_train['charges'] = np.log1p(y_train['charges'])
    

In [14]:

    
    
    y_train['charges'].hist()
    

Out[14]:

    
    
    <AxesSubplot:>

![](__results___files/__results___17_1.png)

## Standard Scaler¶

In [15]:

    
    
    from sklearn.preprocessing import StandardScaler
    scaler = StandardScaler()
    X_train['bmi'] = scaler.fit_transform(X_train[['bmi']])
    X_test['bmi'] = scaler.transform(X_test[['bmi']])
    

## label encoding¶

In [16]:

    
    
    # ëì´ë¥¼ 10ë, 20ë, 30ëë¡ êµ¬ë¶íê¸° ìí´ 10ì ëë ëª« ê°ë§ êµ¬í¨
    X_train['age'] = X_train['age'].apply(lambda x: x//10)
    X_test['age'] = X_test['age'].apply(lambda x: x//10)
    

In [17]:

    
    
    X_train.head(3)
    

Out[17]:

| id | age | bmi | children | sex_female | sex_male | smoker_no | smoker_yes | region_northeast | region_northwest | region_southeast | region_southwest  
---|---|---|---|---|---|---|---|---|---|---|---|---  
209 | 209 | 4 | 1.707232 | 1 | 0 | 1 | 1 | 0 | 1 | 0 | 0 | 0  
540 | 540 | 3 | 1.180775 | 3 | 1 | 0 | 1 | 0 | 0 | 0 | 0 | 1  
747 | 747 | 1 | -1.466991 | 0 | 0 | 1 | 1 | 0 | 0 | 1 | 0 | 0  
  
## Train-Validation Split¶

In [18]:

    
    
    target = y_train['charges']
    X_train = X_train.drop('id', 1)
    
    
    
    /opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only
      
    

In [19]:

    
    
    from sklearn.model_selection import train_test_split
    X_tr, X_val, y_tr, y_val = train_test_split(X_train, target, test_size=0.15, random_state=2022)
    X_tr.shape, X_val.shape, y_tr.shape, y_val.shape
    

Out[19]:

    
    
    ((909, 11), (161, 11), (909,), (161,))

In [20]:

    
    
    from sklearn.ensemble import RandomForestRegressor
    
    rf = RandomForestRegressor()
    rf.fit(X_tr, y_tr)
    pred = rf.predict(X_val)
    

In [21]:

    
    
    from sklearn.metrics import mean_squared_error
    def rmse2(y_true, y_pred):
        return np.sqrt(mean_squared_error(y_true, y_pred))
    
    rmse2(y_val, pred)
    

Out[21]:

    
    
    0.3841485335950636

In [22]:

    
    
    def rmse(y_true, y_pred):
        return np.sqrt(np.mean((y_true-y_pred)**2))
    
    rmse(y_val, pred)
    

Out[22]:

    
    
    0.38414853359506373

In [23]:

    
    
    from xgboost import XGBRegressor
    
    xgb = XGBRegressor()
    xgb.fit(X_tr, y_tr)
    pred = xgb.predict(X_val)
    

In [24]:

    
    
    rmse2(y_val, pred)
    

Out[24]:

    
    
    0.39580148944349686

In [25]:

    
    
    rf.fit(X_train, y_train['charges'])
    pred = rf.predict(X_test.drop('id',1))
    
    
    
    /opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only
      
    

In [26]:

    
    
    pred = np.exp(pred)
    output = pd.DataFrame({'id': y_test['id'], 'charges':pred})
    output.head()
    

Out[26]:

| id | charges  
---|---|---  
1088 | 1088 | 9671.958930  
1157 | 1157 | 4386.203560  
1267 | 1267 | 34234.149629  
506 | 506 | 2802.139413  
659 | 659 | 12530.313876  
  
In [27]:

    
    
    output.to_csv("000000.csv", index=False)
    

# 결과 체점¶

In [28]:

    
    
    rmse(y_test['charges'], pred)
    

Out[28]:

    
    
    4766.892289235487

In [ ]:

    
    
     
    

In [ ]:

    
    
     
    

In [ ]:

    
    
     
    

In [ ]:

    
    
     
    

